{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23da3c16-d70b-4cef-b563-9f92010821ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# import openai\n",
    "import sys\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) \n",
    "\n",
    "# openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "136d9f56-ccc1-483f-b514-5a82d2e09e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTRAT DE LOCATION OU DE COLOCATION D'UN LOGEMENT LOUE MEUBLE CONTRAT DE LOCATION OU DE COLOCATION D'UN LOGEMENT LOUE MEUBLE\n",
      "Soumis au titre Ier bis de la loi du 6 juillet 1989 tendant à améliorer les rapports locatifs\n",
      "Le présent contrat est conclu entre les soussignés :\n",
      "Le bailleur\n",
      "Monsieur\n",
      " \n",
      "Stéphane RICANDA\n",
      " \n",
      "demeurant\n",
      " \n",
      "4591 ROUTE DE GRASSE 06140 TOURRETTES SUR LOUP\n",
      " \n",
      ",\n",
      "Non présent ce jour et représenté par l'Agence en vertu des pouvoirs qui lui sont conférés par le mandat de gestion n°\n",
      "136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'source': 'C:/Users/HP/Desktop/UTBM/Alternance/bail_logement_loue_meuble_a_usage_de_residence_principale_bail_ricanda_boulos-66c59b5c96e54735730163e6.pdf',\n",
       " 'page': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"C:/Users/HP/Desktop/UTBM/Alternance/bail_logement_loue_meuble_a_usage_de_residence_principale_bail_ricanda_boulos-66c59b5c96e54735730163e6.pdf\")\n",
    "\n",
    "pages = loader.load()\n",
    "\n",
    "len(pages)\n",
    "\n",
    "page = pages[1]\n",
    "print(page.page_content[:500])\n",
    "page.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24e4b80",
   "metadata": {},
   "source": [
    "# Video insuffisance cardiaque sur youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc082fca",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'torch' has no attribute 'version' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneric\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GenericLoader\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwhisper\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\Desktop\\UTBM\\Alternance\\Sem1\\Projet_tutore\\AIChatBot\\chatbot_env\\lib\\site-packages\\whisper\\__init__.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Optional, Union\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_audio, log_mel_spectrogram, pad_or_trim\n",
      "File \u001b[1;32mc:\\Users\\HP\\Desktop\\UTBM\\Alternance\\Sem1\\Projet_tutore\\AIChatBot\\chatbot_env\\lib\\site-packages\\torch\\__init__.py:2475\u001b[0m\n\u001b[0;32m   2471\u001b[0m     torch_module_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;18m__name__\u001b[39m, device_type])\n\u001b[0;32m   2472\u001b[0m     sys\u001b[38;5;241m.\u001b[39mmodules[torch_module_name] \u001b[38;5;241m=\u001b[39m module\n\u001b[1;32m-> 2475\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m   2476\u001b[0m     export \u001b[38;5;28;01mas\u001b[39;00m export,\n\u001b[0;32m   2477\u001b[0m     func \u001b[38;5;28;01mas\u001b[39;00m func,\n\u001b[0;32m   2478\u001b[0m     library \u001b[38;5;28;01mas\u001b[39;00m library,\n\u001b[0;32m   2479\u001b[0m     return_types \u001b[38;5;28;01mas\u001b[39;00m return_types,\n\u001b[0;32m   2480\u001b[0m )\n\u001b[0;32m   2481\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_higher_order_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cond \u001b[38;5;28;01mas\u001b[39;00m cond, while_loop \u001b[38;5;28;01mas\u001b[39;00m while_loop\n\u001b[0;32m   2482\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m vmap \u001b[38;5;28;01mas\u001b[39;00m vmap\n",
      "File \u001b[1;32mc:\\Users\\HP\\Desktop\\UTBM\\Alternance\\Sem1\\Projet_tutore\\AIChatBot\\chatbot_env\\lib\\site-packages\\torch\\export\\__init__.py:64\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msymbolic_shapes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StrictMinMaxConstraint\n\u001b[0;32m     44\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConstraint\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDim\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnflattenedModule\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     61\u001b[0m ]\n\u001b[1;32m---> 64\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdynamic_shapes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Constraint, Dim, dims, ShapesCollection\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexported_program\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExportedProgram, ModuleCallEntry, ModuleCallSignature\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_signature\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExportBackwardSignature, ExportGraphSignature\n",
      "File \u001b[1;32mc:\\Users\\HP\\Desktop\\UTBM\\Alternance\\Sem1\\Projet_tutore\\AIChatBot\\chatbot_env\\lib\\site-packages\\torch\\export\\dynamic_shapes.py:23\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pytree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     12\u001b[0m     _get_node_type,\n\u001b[0;32m     13\u001b[0m     BUILTIN_TYPES,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m     tree_map_with_path,\n\u001b[0;32m     21\u001b[0m )\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexported_program\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExportedProgram\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msympy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Symbol\n",
      "File \u001b[1;32mc:\\Users\\HP\\Desktop\\UTBM\\Alternance\\Sem1\\Projet_tutore\\AIChatBot\\chatbot_env\\lib\\site-packages\\torch\\export\\exported_program.py:26\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcontextlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m contextmanager\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     13\u001b[0m     Any,\n\u001b[0;32m     14\u001b[0m     Callable,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m     Union,\n\u001b[0;32m     24\u001b[0m )\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_higher_order_ops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m autograd_not_implemented\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_library\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfake_class_registry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FakeScriptObject\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m first_call_function_nn_module_stack\n",
      "File \u001b[1;32mc:\\Users\\HP\\Desktop\\UTBM\\Alternance\\Sem1\\Projet_tutore\\AIChatBot\\chatbot_env\\lib\\site-packages\\torch\\_higher_order_ops\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_higher_order_ops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcond\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cond\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_higher_order_ops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflex_attention\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      3\u001b[0m     flex_attention,\n\u001b[0;32m      4\u001b[0m     flex_attention_backward,\n\u001b[0;32m      5\u001b[0m )\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_higher_order_ops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhints_wrap\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hints_wrapper\n",
      "File \u001b[1;32mc:\\Users\\HP\\Desktop\\UTBM\\Alternance\\Sem1\\Projet_tutore\\AIChatBot\\chatbot_env\\lib\\site-packages\\torch\\_higher_order_ops\\cond.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_subclasses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional_tensor\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pytree\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpytree\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DispatchKey\n",
      "File \u001b[1;32mc:\\Users\\HP\\Desktop\\UTBM\\Alternance\\Sem1\\Projet_tutore\\AIChatBot\\chatbot_env\\lib\\site-packages\\torch\\_subclasses\\functional_tensor.py:9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, ContextManager, Dict, List, Optional, Tuple, Union\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_inductor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01minductor_config\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pytree\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpytree\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _functionalization_reapply_views_tls \u001b[38;5;28;01mas\u001b[39;00m _reapply_views\n",
      "File \u001b[1;32mc:\\Users\\HP\\Desktop\\UTBM\\Alternance\\Sem1\\Projet_tutore\\AIChatBot\\chatbot_env\\lib\\site-packages\\torch\\_inductor\\config.py:44\u001b[0m\n\u001b[0;32m     40\u001b[0m verbose_progress \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# use fx aot graph codegen cache\u001b[39;00m\n\u001b[0;32m     43\u001b[0m fx_graph_cache \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m---> 44\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTORCHINDUCTOR_FX_GRAPH_CACHE\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_fbcode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     45\u001b[0m )\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# use remote fx aot graph codegen cache\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# False: Disables the cache\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# True: Enables the cache\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# None: Not set -- Off for OSS, JustKnobs based for internal\u001b[39;00m\n\u001b[0;32m     51\u001b[0m fx_graph_remote_cache: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m fx_graph_remote_cache_default()\n",
      "File \u001b[1;32mc:\\Users\\HP\\Desktop\\UTBM\\Alternance\\Sem1\\Projet_tutore\\AIChatBot\\chatbot_env\\lib\\site-packages\\torch\\_inductor\\config.py:9\u001b[0m, in \u001b[0;36mis_fbcode\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_fbcode\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mversion\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgit_version\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'torch' has no attribute 'version' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders.generic import GenericLoader\n",
    "import whisper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50de754f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader\n",
    "import whisper\n",
    "\n",
    "# Initialize Whisper Model\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "# Function to transcribe audio\n",
    "def transcribe_audio(audio_file_path):\n",
    "    print(f\"Transcribing audio file: {audio_file_path}\")\n",
    "    result = model.transcribe(str(audio_file_path))\n",
    "    return result[\"text\"]\n",
    "\n",
    "# YouTube URL and save directory\n",
    "url = \"https://www.youtube.com/watch?v=v_CTlg32-tI&ab_channel=HopitauxUniversitairesdeGen%C3%A8ve\"\n",
    "url_1 = \"https://www.youtube.com/watch?v=gqge5Ni-qq0&ab_channel=AlloDocteurs\"\n",
    "save_dir = \"videos\"\n",
    "\n",
    "# Step 1: Use YoutubeAudioLoader to download and yield audio files\n",
    "audio_loader = YoutubeAudioLoader([url, url_1], save_dir)\n",
    "\n",
    "# Use yield_blobs() to get audio blobs\n",
    "for blob in audio_loader.yield_blobs():\n",
    "    # blob.path contains the path to the audio file\n",
    "    transcription = transcribe_audio(blob.path)\n",
    "    print(f\"Transcription for {blob.path}:\\n{transcription}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ddbb96",
   "metadata": {},
   "source": [
    "## Data from URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a43a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://en.wikipedia.org/wiki/Artificial_intelligence\")\n",
    "\n",
    "pages = loader.load()\n",
    "\n",
    "print(pages[0].page_content[:500])\n",
    "\n",
    "##TODO: Fix data format \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d4a9c8",
   "metadata": {},
   "source": [
    "# Export Data from Notion\n",
    "\n",
    "TODO: How to export data from notion databases to notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f375c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1402161",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 26\n",
    "chunk_overlap = 4\n",
    "\n",
    "r_splitter = RecursiveCharacterTextSplitter(chunk_size = chunk_size, chunk_overlap = chunk_overlap)\n",
    "c_splitter = CharacterTextSplitter(chunk_size = chunk_size, chunk_overlap = chunk_overlap)\n",
    "\n",
    "text_1 = 'abcdefghijklmnopqrstuvwxyz'\n",
    "\n",
    "r_splitter.split_text(text_1)\n",
    "\n",
    "text_2 = 'abcdefghijklmnopqrstuvwxyzabcedfg'\n",
    "\n",
    "r_splitter.split_text(text_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd351ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_3 = \"a b c d e f g h i j k l m n o p q r s t u v w x y z\"\n",
    "\n",
    "r_splitter.split_text(text_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957b1323",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_splitter.split_text(text_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860a6ed5",
   "metadata": {},
   "source": [
    "# Vectors embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0938ca14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "embeddingModel = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "sentence1 = \"I like dogs\"\n",
    "sentence2 = \"I like canines\"\n",
    "sentence3 = \"The weather is ugly outside\"\n",
    "\n",
    "embedding1 = embeddingModel.encode(sentence1)\n",
    "embedding2 = embeddingModel.encode(sentence2)\n",
    "embedding3 = embeddingModel.encode(sentence3)\n",
    "\n",
    "import numpy as np\n",
    "similarity1_2 = np.dot(embedding1, embedding2) / (np.linalg.norm(embedding1) * np.linalg.norm(embedding2))\n",
    "similarity1_3 = np.dot(embedding1, embedding3) / (np.linalg.norm(embedding1) * np.linalg.norm(embedding3))\n",
    "similarity2_3 = np.dot(embedding2, embedding3) / (np.linalg.norm(embedding2) * np.linalg.norm(embedding3))\n",
    "\n",
    "print(f\"Similarity between '{sentence1}' and '{sentence2}': {similarity1_2}\")\n",
    "print(f\"Similarity between '{sentence1}' and '{sentence3}': {similarity1_3}\")\n",
    "print(f\"Similarity between '{sentence2}' and '{sentence3}': {similarity2_3}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f283b5",
   "metadata": {},
   "source": [
    "# Creating splits(chunks) from pdf data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a28b707",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4c0292",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = [\n",
    "    PyPDFLoader(\"docs/pdfData/adhantibe.pdf\"),\n",
    "    PyPDFLoader(\"docs/pdfData/adhantibe.pdf\"),  # Duplicate\n",
    "    PyPDFLoader(\"docs/pdfData/attestationcaf.pdf\"),\n",
    "    PyPDFLoader(\"docs/pdfData/SecondeLogment.pdf\")\n",
    "]\n",
    "\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())\n",
    "print(len(docs))\n",
    "print(docs[0].metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f74a6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=150\n",
    ")\n",
    "splits = text_splitter.split_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7313525",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(splits)\n",
    "print(\"split 0\\n\")\n",
    "print(splits[0])\n",
    "print(\"split 1\\n\")\n",
    "print(splits[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb0a7dc",
   "metadata": {},
   "source": [
    "# Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72bfe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771f9e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rmdir /s /q chroma_db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110f437d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# Wrap the SentenceTransformer model\n",
    "embeddingModel = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Use Chroma to store the vector database\n",
    "persist_directory = \"./chroma_db\"\n",
    "vectorDB = Chroma.from_documents(documents=splits, embedding=embeddingModel, persist_directory=persist_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3e0573",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vectorDB._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afea6c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \" SecondeLogemnet.\"\n",
    "\n",
    "docs = vectorDB.similarity_search(question, k = 4)\n",
    "for doc in docs:\n",
    "    print(doc.metadata)\n",
    "print(docs[0].page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
